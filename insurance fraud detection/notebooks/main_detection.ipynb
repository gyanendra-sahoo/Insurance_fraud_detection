{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d944a11e-92a5-43fd-9cde-b5a836f38a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚗 INSURANCE FRAUD DETECTION SYSTEM\n",
      "======================================================================\n",
      "\n",
      "🔧 Choose an option:\n",
      "1. Train new model (creates synthetic data)\n",
      "2. Train model with your data\n",
      "3. Predict fraud on new data\n",
      "4. Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "➤ Enter your choice (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Predicting fraud on new data...\n",
      "\n",
      "======================================================================\n",
      "🔍 INSURANCE FRAUD PREDICTION\n",
      "======================================================================\n",
      "\n",
      "📁 Please enter the CSV file path for fraud prediction:\n",
      "   Examples:\n",
      "   • Auto_Insurance_Fraud_Claims_File03.csv\n",
      "   • data/claims_2024.csv\n",
      "   • /full/path/to/your/file.csv\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "➤ Enter file path:  Auto_Insurance_Fraud_Claims_File03.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File found: Auto_Insurance_Fraud_Claims_File03.csv\n",
      "\n",
      "📂 Loading data from: Auto_Insurance_Fraud_Claims_File03.csv\n",
      "✅ Data loaded: 10000 records, 52 columns\n",
      "✅ Model and components loaded successfully!\n",
      "🔧 Preprocessing data...\n",
      "\n",
      "❌ An unexpected error occurred: 'bool' object has no attribute 'astype'\n",
      "Please try again or contact support.\n"
     ]
    }
   ],
   "source": [
    "# complete_fraud_detection_system.py\n",
    "# Complete Insurance Fraud Detection System with Training and Prediction\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import xgboost as xgb\n",
    "from sklearn.utils import resample\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "class FraudDetectionSystem:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "        self.feature_columns = None\n",
    "        self.label_encoders = {}\n",
    "        \n",
    "    def create_synthetic_data(self, n_samples=10000):\n",
    "        \"\"\"\n",
    "        Create synthetic insurance fraud data for training\n",
    "        \"\"\"\n",
    "        print(\"🔧 Creating synthetic training data...\")\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        data = {\n",
    "            'Policy_Num': [f'POL{str(i).zfill(6)}' for i in range(n_samples)],\n",
    "            'Age': np.random.randint(18, 80, n_samples),\n",
    "            'Gender': np.random.choice(['Male', 'Female'], n_samples, p=[0.6, 0.4]),\n",
    "            'Education': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], n_samples, p=[0.4, 0.35, 0.2, 0.05]),\n",
    "            'Occupation': np.random.choice(['Engineer', 'Doctor', 'Teacher', 'Student', 'Other'], n_samples, p=[0.2, 0.15, 0.15, 0.1, 0.4]),\n",
    "            'Annual_Income': np.random.lognormal(10.5, 0.5, n_samples).astype(int),\n",
    "            'Policy_State': np.random.choice(['CA', 'TX', 'NY', 'FL', 'IL'], n_samples, p=[0.3, 0.25, 0.2, 0.15, 0.1]),\n",
    "            'Vehicle_Cost': np.random.lognormal(10, 0.3, n_samples).astype(int),\n",
    "            'Vehicle_Age': np.random.randint(0, 20, n_samples),\n",
    "            'Auto_Make': np.random.choice(['Toyota', 'Honda', 'Ford', 'BMW', 'Mercedes'], n_samples, p=[0.3, 0.25, 0.2, 0.15, 0.1]),\n",
    "            'Auto_Model': np.random.choice(['Sedan', 'SUV', 'Truck', 'Coupe', 'Hatchback'], n_samples, p=[0.3, 0.25, 0.2, 0.15, 0.1]),\n",
    "            'Total_Claim': np.random.lognormal(8, 0.7, n_samples).astype(int),\n",
    "            'Injury_Claim': np.random.lognormal(7, 0.8, n_samples).astype(int),\n",
    "            'Property_Claim': np.random.lognormal(7.5, 0.6, n_samples).astype(int),\n",
    "            'Vehicle_Claim': np.random.lognormal(7.8, 0.5, n_samples).astype(int),\n",
    "            'Accident_Severity': np.random.choice(['Minor', 'Major', 'Total Loss'], n_samples, p=[0.6, 0.3, 0.1]),\n",
    "            'Accident_Type': np.random.choice(['Single Vehicle', 'Multi-Vehicle', 'Parked Car'], n_samples, p=[0.4, 0.5, 0.1]),\n",
    "            'Collision_Type': np.random.choice(['Front', 'Rear', 'Side', 'Other'], n_samples, p=[0.3, 0.25, 0.25, 0.2]),\n",
    "            'Accident_Hour': np.random.randint(0, 24, n_samples),\n",
    "            'Number_of_Vehicles_Involved': np.random.choice([1, 2, 3, 4], n_samples, p=[0.4, 0.4, 0.15, 0.05]),\n",
    "            'Bodily_Injuries': np.random.randint(0, 5, n_samples),\n",
    "            'Witnesses': np.random.randint(0, 4, n_samples),\n",
    "            'Police_Report_Available': np.random.choice(['Yes', 'No'], n_samples, p=[0.7, 0.3]),\n",
    "            'authorities_contacted': np.random.choice(['Police', 'Fire', 'Ambulance', 'None'], n_samples, p=[0.5, 0.1, 0.2, 0.2]),\n",
    "            'Deductible': np.random.choice([500, 1000, 1500, 2000], n_samples, p=[0.3, 0.4, 0.2, 0.1]),\n",
    "            'Driver_Rating': np.random.randint(1, 5, n_samples),\n",
    "            'Days_Policy_Accident': np.random.randint(1, 365, n_samples),\n",
    "            'Days_Policy_Claim': np.random.randint(1, 30, n_samples),\n",
    "            'Past_Number_of_Claims': np.random.poisson(0.5, n_samples),\n",
    "            'SafeDriver': np.random.choice(['Yes', 'No'], n_samples, p=[0.8, 0.2])\n",
    "        }\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Create fraud labels based on logical rules\n",
    "        fraud_probability = np.zeros(n_samples)\n",
    "        \n",
    "        # High fraud indicators\n",
    "        fraud_probability += (df['Total_Claim'] > 50000) * 0.3\n",
    "        fraud_probability += (df['Days_Policy_Claim'] < 7) * 0.25\n",
    "        fraud_probability += (df['Police_Report_Available'] == 'No') * 0.2\n",
    "        fraud_probability += (df['Witnesses'] == 0) * 0.15\n",
    "        fraud_probability += (df['Past_Number_of_Claims'] > 2) * 0.2\n",
    "        fraud_probability += (df['Accident_Hour'].between(22, 6)) * 0.1\n",
    "        fraud_probability += (df['SafeDriver'] == 'No') * 0.15\n",
    "        fraud_probability += (df['Accident_Severity'] == 'Total Loss') * 0.2\n",
    "        \n",
    "        # Add some randomness\n",
    "        fraud_probability += np.random.random(n_samples) * 0.1\n",
    "        \n",
    "        # Clip probabilities\n",
    "        fraud_probability = np.clip(fraud_probability, 0, 1)\n",
    "        \n",
    "        # Generate fraud labels\n",
    "        df['Fraud'] = (np.random.random(n_samples) < fraud_probability).astype(int)\n",
    "        \n",
    "        print(f\"✅ Synthetic data created: {len(df)} records\")\n",
    "        print(f\"   Fraud cases: {df['Fraud'].sum()} ({df['Fraud'].mean()*100:.1f}%)\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def preprocess_data(self, df, is_training=True):\n",
    "        \"\"\"\n",
    "        Preprocess the data for training or prediction\n",
    "        \"\"\"\n",
    "        print(\"🔧 Preprocessing data...\")\n",
    "        \n",
    "        # Create a copy to avoid modifying original\n",
    "        data = df.copy()\n",
    "        \n",
    "        # Handle missing values\n",
    "        numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "        categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "        \n",
    "        # Fill numeric missing values with median\n",
    "        for col in numeric_cols:\n",
    "            if data[col].isnull().any():\n",
    "                data[col].fillna(data[col].median(), inplace=True)\n",
    "        \n",
    "        # Fill categorical missing values with mode\n",
    "        for col in categorical_cols:\n",
    "            if data[col].isnull().any():\n",
    "                data[col].fillna(data[col].mode()[0], inplace=True)\n",
    "        \n",
    "        # Create engineered features\n",
    "        data['Claim_to_Vehicle_Ratio'] = data.get('Total_Claim', 0) / (data.get('Vehicle_Cost', 1) + 1)\n",
    "        data['Age_Vehicle_Interaction'] = data.get('Age', 0) * data.get('Vehicle_Age', 0)\n",
    "        data['High_Risk_Hour'] = ((data.get('Accident_Hour', 12) >= 22) | (data.get('Accident_Hour', 12) <= 6)).astype(int)\n",
    "        data['Quick_Claim'] = (data.get('Days_Policy_Claim', 30) <= 7).astype(int)\n",
    "        data['High_Claim_Amount'] = (data.get('Total_Claim', 0) > data.get('Total_Claim', 0).quantile(0.9) if 'Total_Claim' in data.columns else 0).astype(int)\n",
    "        data['Multiple_Claims_History'] = (data.get('Past_Number_of_Claims', 0) > 1).astype(int)\n",
    "        \n",
    "        # Encode categorical variables\n",
    "        categorical_features = ['Gender', 'Education', 'Occupation', 'Policy_State', 'Auto_Make', \n",
    "                              'Auto_Model', 'Accident_Severity', 'Accident_Type', 'Collision_Type',\n",
    "                              'Police_Report_Available', 'authorities_contacted', 'SafeDriver']\n",
    "        \n",
    "        for col in categorical_features:\n",
    "            if col in data.columns:\n",
    "                if is_training:\n",
    "                    # Create and store label encoder for training\n",
    "                    le = LabelEncoder()\n",
    "                    data[col] = le.fit_transform(data[col].astype(str))\n",
    "                    self.label_encoders[col] = le\n",
    "                else:\n",
    "                    # Use existing label encoder for prediction\n",
    "                    if col in self.label_encoders:\n",
    "                        try:\n",
    "                            data[col] = self.label_encoders[col].transform(data[col].astype(str))\n",
    "                        except ValueError:\n",
    "                            # Handle unseen categories\n",
    "                            data[col] = 0\n",
    "                    else:\n",
    "                        data[col] = 0\n",
    "        \n",
    "        # Remove non-feature columns\n",
    "        columns_to_remove = ['Policy_Num', 'Fraud'] if 'Policy_Num' in data.columns else []\n",
    "        for col in columns_to_remove:\n",
    "            if col in data.columns:\n",
    "                data = data.drop(columns=[col])\n",
    "        \n",
    "        # Store feature columns for consistency\n",
    "        if is_training:\n",
    "            self.feature_columns = data.columns.tolist()\n",
    "        else:\n",
    "            # Ensure prediction data has same columns as training\n",
    "            for col in self.feature_columns:\n",
    "                if col not in data.columns:\n",
    "                    data[col] = 0\n",
    "            data = data[self.feature_columns]\n",
    "        \n",
    "        print(f\"✅ Preprocessing complete: {data.shape[1]} features\")\n",
    "        return data\n",
    "    \n",
    "    def train_model(self, df=None):\n",
    "        \"\"\"\n",
    "        Train the fraud detection model\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"🚀 TRAINING FRAUD DETECTION MODEL\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Create synthetic data if none provided\n",
    "        if df is None:\n",
    "            df = self.create_synthetic_data()\n",
    "        \n",
    "        # Separate features and target\n",
    "        X = self.preprocess_data(df, is_training=True)\n",
    "        y = df['Fraud'].values\n",
    "        \n",
    "        print(f\"\\n📊 Training Data Summary:\")\n",
    "        print(f\"   Features: {X.shape[1]}\")\n",
    "        print(f\"   Samples: {X.shape[0]}\")\n",
    "        print(f\"   Fraud Rate: {y.mean()*100:.1f}%\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Scale features\n",
    "        self.scaler = StandardScaler()\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        # Train XGBoost model\n",
    "        print(\"\\n🤖 Training XGBoost model...\")\n",
    "        self.model = xgb.XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            eval_metric='logloss'\n",
    "        )\n",
    "        \n",
    "        self.model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Evaluate model\n",
    "        train_score = self.model.score(X_train_scaled, y_train)\n",
    "        test_score = self.model.score(X_test_scaled, y_test)\n",
    "        \n",
    "        y_pred = self.model.predict(X_test_scaled)\n",
    "        y_pred_proba = self.model.predict_proba(X_test_scaled)[:, 1]\n",
    "        \n",
    "        auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "        \n",
    "        print(f\"\\n📈 Model Performance:\")\n",
    "        print(f\"   Training Accuracy: {train_score:.4f}\")\n",
    "        print(f\"   Testing Accuracy: {test_score:.4f}\")\n",
    "        print(f\"   AUC Score: {auc_score:.4f}\")\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(self.model, X_train_scaled, y_train, cv=5, scoring='roc_auc')\n",
    "        print(f\"   CV AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        \n",
    "        # Classification report\n",
    "        print(f\"\\n📋 Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred, target_names=['No Fraud', 'Fraud']))\n",
    "        \n",
    "        # Save model and components\n",
    "        self.save_model()\n",
    "        \n",
    "        # Create training visualizations\n",
    "        self.create_training_plots(X_test_scaled, y_test, y_pred_proba)\n",
    "        \n",
    "        print(\"\\n✅ Model training completed successfully!\")\n",
    "        return self.model\n",
    "    \n",
    "    def save_model(self):\n",
    "        \"\"\"\n",
    "        Save the trained model and components\n",
    "        \"\"\"\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        \n",
    "        # Save model\n",
    "        joblib.dump(self.model, 'fraud_detection_xgb_model.pkl')\n",
    "        print(f\"💾 Model saved: fraud_detection_xgb_model.pkl\")\n",
    "        \n",
    "        # Save scaler\n",
    "        joblib.dump(self.scaler, 'fraud_model_scaler.pkl')\n",
    "        print(f\"💾 Scaler saved: fraud_model_scaler.pkl\")\n",
    "        \n",
    "        # Save feature columns\n",
    "        joblib.dump(self.feature_columns, 'fraud_model_features.pkl')\n",
    "        print(f\"💾 Features saved: fraud_model_features.pkl\")\n",
    "        \n",
    "        # Save label encoders\n",
    "        joblib.dump(self.label_encoders, 'fraud_label_encoders.pkl')\n",
    "        print(f\"💾 Encoders saved: fraud_label_encoders.pkl\")\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"\n",
    "        Load the trained model and components\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.model = joblib.load('fraud_detection_xgb_model.pkl')\n",
    "            self.scaler = joblib.load('fraud_model_scaler.pkl')\n",
    "            self.feature_columns = joblib.load('fraud_model_features.pkl')\n",
    "            self.label_encoders = joblib.load('fraud_label_encoders.pkl')\n",
    "            print(\"✅ Model and components loaded successfully!\")\n",
    "            return True\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"❌ Error loading model: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def create_training_plots(self, X_test, y_test, y_pred_proba):\n",
    "        \"\"\"\n",
    "        Create training evaluation plots\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # ROC Curve\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "        \n",
    "        axes[0, 0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_score:.3f})')\n",
    "        axes[0, 0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        axes[0, 0].set_xlabel('False Positive Rate')\n",
    "        axes[0, 0].set_ylabel('True Positive Rate')\n",
    "        axes[0, 0].set_title('ROC Curve')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True)\n",
    "        \n",
    "        # Feature Importance\n",
    "        if hasattr(self.model, 'feature_importances_'):\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': self.feature_columns,\n",
    "                'importance': self.model.feature_importances_\n",
    "            }).sort_values('importance', ascending=True).tail(15)\n",
    "            \n",
    "            axes[0, 1].barh(importance_df['feature'], importance_df['importance'])\n",
    "            axes[0, 1].set_title('Top 15 Feature Importances')\n",
    "            axes[0, 1].set_xlabel('Importance')\n",
    "        \n",
    "        # Probability Distribution\n",
    "        fraud_probs = y_pred_proba[y_test == 1]\n",
    "        normal_probs = y_pred_proba[y_test == 0]\n",
    "        \n",
    "        axes[1, 0].hist(normal_probs, bins=30, alpha=0.7, label='No Fraud', color='blue', density=True)\n",
    "        axes[1, 0].hist(fraud_probs, bins=30, alpha=0.7, label='Fraud', color='red', density=True)\n",
    "        axes[1, 0].set_xlabel('Fraud Probability')\n",
    "        axes[1, 0].set_ylabel('Density')\n",
    "        axes[1, 0].set_title('Probability Distribution by Class')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True)\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        y_pred_binary = (y_pred_proba > 0.5).astype(int)\n",
    "        cm = confusion_matrix(y_test, y_pred_binary)\n",
    "        \n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 1])\n",
    "        axes[1, 1].set_title('Confusion Matrix')\n",
    "        axes[1, 1].set_xlabel('Predicted')\n",
    "        axes[1, 1].set_ylabel('Actual')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save plot\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        plot_filename = f\"model_evaluation_{timestamp}.png\"\n",
    "        plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"📊 Training plots saved: {plot_filename}\")\n",
    "        plt.show()\n",
    "    \n",
    "    def get_user_input(self):\n",
    "        \"\"\"\n",
    "        Get CSV file path from user input\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"🔍 INSURANCE FRAUD PREDICTION\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        while True:\n",
    "            print(\"\\n📁 Please enter the CSV file path for fraud prediction:\")\n",
    "            print(\"   Examples:\")\n",
    "            print(\"   • Auto_Insurance_Fraud_Claims_File03.csv\")\n",
    "            print(\"   • data/claims_2024.csv\")\n",
    "            print(\"   • /full/path/to/your/file.csv\")\n",
    "            \n",
    "            file_path = input(\"\\n➤ Enter file path: \").strip()\n",
    "            \n",
    "            if not file_path:\n",
    "                print(\"❌ Please enter a valid file path!\")\n",
    "                continue\n",
    "            \n",
    "            # Add .csv extension if not present\n",
    "            if not file_path.endswith('.csv'):\n",
    "                file_path += '.csv'\n",
    "            \n",
    "            # Check if file exists\n",
    "            if os.path.exists(file_path):\n",
    "                print(f\"✅ File found: {file_path}\")\n",
    "                return file_path\n",
    "            else:\n",
    "                print(f\"❌ File not found: {file_path}\")\n",
    "                retry = input(\"   Try again? (y/n): \").strip().lower()\n",
    "                if retry != 'y':\n",
    "                    return None\n",
    "    \n",
    "    def predict_fraud(self, df=None):\n",
    "        \"\"\"\n",
    "        Predict fraud for new data\n",
    "        \"\"\"\n",
    "        # Get file path if dataframe not provided\n",
    "        if df is None:\n",
    "            file_path = self.get_user_input()\n",
    "            if not file_path:\n",
    "                print(\"❌ Exiting prediction.\")\n",
    "                return None\n",
    "                \n",
    "            try:\n",
    "                print(f\"\\n📂 Loading data from: {file_path}\")\n",
    "                df = pd.read_csv(file_path)\n",
    "                print(f\"✅ Data loaded: {df.shape[0]} records, {df.shape[1]} columns\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error loading data: {str(e)}\")\n",
    "                return None\n",
    "        \n",
    "        # Load model if not already loaded\n",
    "        if self.model is None:\n",
    "            if not self.load_model():\n",
    "                print(\"❌ Please train the model first!\")\n",
    "                return None\n",
    "        \n",
    "        # Store original data for results\n",
    "        original_df = df.copy()\n",
    "        \n",
    "        # Preprocess data\n",
    "        X = self.preprocess_data(df, is_training=False)\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        # Make predictions\n",
    "        print(\"\\n🤖 Making fraud predictions...\")\n",
    "        predictions = self.model.predict(X_scaled)\n",
    "        probabilities = self.model.predict_proba(X_scaled)[:, 1]\n",
    "        \n",
    "        # Create risk levels\n",
    "        risk_levels = pd.cut(probabilities, \n",
    "                           bins=[0, 0.33, 0.66, 1.0], \n",
    "                           labels=[\"Low\", \"Medium\", \"High\"])\n",
    "        \n",
    "        # Create results dataframe\n",
    "        results_df = pd.DataFrame({\n",
    "            'Claim_ID': original_df.get('Policy_Num', range(len(original_df))),\n",
    "            'Fraud_Prediction': predictions,\n",
    "            'Fraud_Probability': probabilities.round(4),\n",
    "            'Risk_Level': risk_levels,\n",
    "            'Fraud_Label': ['Fraud' if pred == 1 else 'No Fraud' for pred in predictions]\n",
    "        })\n",
    "        \n",
    "        # Display results summary\n",
    "        self.display_results_summary(results_df)\n",
    "        \n",
    "        # Save results\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        output_file = f\"fraud_predictions_{timestamp}.csv\"\n",
    "        results_df.to_csv(output_file, index=False)\n",
    "        print(f\"\\n💾 Results saved to: {output_file}\")\n",
    "        \n",
    "        # Create prediction visualizations\n",
    "        self.create_prediction_plots(results_df, original_df)\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def display_results_summary(self, results_df):\n",
    "        \"\"\"\n",
    "        Display prediction results summary\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"📊 PREDICTION RESULTS SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        total_records = len(results_df)\n",
    "        fraud_cases = sum(results_df['Fraud_Prediction'])\n",
    "        fraud_percentage = (fraud_cases / total_records) * 100\n",
    "        \n",
    "        print(f\"📈 Overall Statistics:\")\n",
    "        print(f\"   Total records analyzed: {total_records:,}\")\n",
    "        print(f\"   Predicted fraud cases: {fraud_cases:,} ({fraud_percentage:.1f}%)\")\n",
    "        print(f\"   Average fraud probability: {results_df['Fraud_Probability'].mean():.4f}\")\n",
    "        print(f\"   Highest fraud probability: {results_df['Fraud_Probability'].max():.4f}\")\n",
    "        \n",
    "        print(f\"\\n🚨 Risk Level Breakdown:\")\n",
    "        risk_counts = results_df['Risk_Level'].value_counts()\n",
    "        for level in ['High', 'Medium', 'Low']:\n",
    "            if level in risk_counts.index:\n",
    "                count = risk_counts[level]\n",
    "                percentage = (count / total_records) * 100\n",
    "                print(f\"   {level} Risk: {count:,} cases ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Show top risk cases\n",
    "        if fraud_cases > 0:\n",
    "            print(f\"\\n⚠️  Top 5 Highest Risk Cases:\")\n",
    "            top_5 = results_df.nlargest(5, 'Fraud_Probability')\n",
    "            for idx, row in top_5.iterrows():\n",
    "                print(f\"   Claim {row['Claim_ID']}: {row['Fraud_Probability']:.4f} ({row['Risk_Level']} Risk)\")\n",
    "    \n",
    "    def create_prediction_plots(self, results_df, original_df):\n",
    "        \"\"\"\n",
    "        Create comprehensive prediction visualizations\n",
    "        \"\"\"\n",
    "        print(\"\\n📊 Creating prediction visualizations...\")\n",
    "        \n",
    "        fig = plt.figure(figsize=(20, 15))\n",
    "        \n",
    "        # 1. Fraud Distribution Pie Chart\n",
    "        plt.subplot(3, 4, 1)\n",
    "        fraud_counts = results_df['Fraud_Label'].value_counts()\n",
    "        colors = ['#2ecc71', '#e74c3c']\n",
    "        plt.pie(fraud_counts.values, labels=fraud_counts.index, autopct='%1.1f%%', \n",
    "                colors=colors, startangle=90, explode=(0.05, 0.05))\n",
    "        plt.title('Fraud vs Non-Fraud Distribution', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # 2. Risk Level Distribution\n",
    "        plt.subplot(3, 4, 2)\n",
    "        risk_counts = results_df['Risk_Level'].value_counts()\n",
    "        colors_risk = ['#e74c3c', '#f39c12', '#2ecc71']\n",
    "        bars = plt.bar(risk_counts.index, risk_counts.values, color=colors_risk)\n",
    "        plt.title('Risk Level Distribution', fontsize=12, fontweight='bold')\n",
    "        plt.ylabel('Number of Cases')\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                    f'{int(height)}', ha='center', va='bottom')\n",
    "        \n",
    "        # 3. Probability Distribution\n",
    "        plt.subplot(3, 4, 3)\n",
    "        plt.hist(results_df['Fraud_Probability'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        plt.axvline(results_df['Fraud_Probability'].mean(), color='red', linestyle='--', \n",
    "                   label=f'Mean: {results_df[\"Fraud_Probability\"].mean():.3f}')\n",
    "        plt.title('Fraud Probability Distribution', fontsize=12, fontweight='bold')\n",
    "        plt.xlabel('Fraud Probability')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Risk Level Box Plot\n",
    "        plt.subplot(3, 4, 4)\n",
    "        risk_order = ['Low', 'Medium', 'High']\n",
    "        sns.boxplot(data=results_df, x='Risk_Level', y='Fraud_Probability', order=risk_order)\n",
    "        plt.title('Fraud Probability by Risk Level', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # 5. Top 10 High Risk Cases\n",
    "        plt.subplot(3, 4, 5)\n",
    "        top_10 = results_df.nlargest(10, 'Fraud_Probability')\n",
    "        colors_top = ['red' if prob > 0.8 else 'orange' if prob > 0.5 else 'yellow' \n",
    "                     for prob in top_10['Fraud_Probability']]\n",
    "        plt.barh(range(len(top_10)), top_10['Fraud_Probability'], color=colors_top)\n",
    "        plt.yticks(range(len(top_10)), [f\"Claim {str(id)[:8]}\" for id in top_10['Claim_ID']])\n",
    "        plt.title('Top 10 Highest Risk Cases', fontsize=12, fontweight='bold')\n",
    "        plt.xlabel('Fraud Probability')\n",
    "        \n",
    "        # 6-12: Additional analysis plots based on available columns\n",
    "        available_plots = [\n",
    "            ('Total_Claim', 'Total Claim Amount vs Fraud Probability', 6),\n",
    "            ('Age', 'Age Distribution by Fraud Prediction', 7),\n",
    "            ('Vehicle_Cost', 'Vehicle Cost vs Fraud Risk', 8),\n",
    "            ('Annual_Income', 'Income vs Fraud Probability', 9),\n",
    "            ('Past_Number_of_Claims', 'Claims History vs Fraud Risk', 10),\n",
    "        ]\n",
    "        \n",
    "        for col, title, subplot_num in available_plots:\n",
    "            plt.subplot(3, 4, subplot_num)\n",
    "            if col in original_df.columns:\n",
    "                if col in ['Total_Claim', 'Vehicle_Cost', 'Annual_Income']:\n",
    "                    scatter_colors = ['red' if x == 1 else 'blue' for x in results_df['Fraud_Prediction']]\n",
    "                    plt.scatter(original_df[col], results_df['Fraud_Probability'], \n",
    "                              c=scatter_colors, alpha=0.6, s=20)\n",
    "                    plt.xlabel(col.replace('_', ' '))\n",
    "                    plt.ylabel('Fraud Probability')\n",
    "                elif col in ['Age', 'Past_Number_of_Claims']:\n",
    "                    fraud_by_col = original_df.groupby(col)[results_df['Fraud_Prediction'] == 1].mean()\n",
    "                    plt.plot(fraud_by_col.index, fraud_by_col.values, marker='o', color='purple')\n",
    "                    plt.xlabel(col.replace('_', ' '))\n",
    "                    plt.ylabel('Fraud Rate')\n",
    "                    plt.grid(True, alpha=0.3)\n",
    "                plt.title(title, fontsize=10, fontweight='bold')\n",
    "            else:\n",
    "                plt.text(0.5, 0.5, f'{col}\\ncolumn not found', ha='center', va='center', \n",
    "                        transform=plt.gca().transAxes, fontsize=10)\n",
    "                plt.title(title, fontsize=10, fontweight='bold')\n",
    "        \n",
    "        # Summary Statistics Plot\n",
    "        plt.subplot(3, 4, 11)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Calculate statistics\n",
    "        total_cases = len(results_df)\n",
    "        fraud_cases = sum(results_df['Fraud_Prediction'])\n",
    "        high_risk = sum(results_df['Risk_Level'] == 'High')\n",
    "        medium_risk = sum(results_df['Risk_Level'] == 'Medium')\n",
    "        low_risk = sum(results_df['Risk_Level'] == 'Low')\n",
    "        avg_prob = results_df['Fraud_Probability'].mean()\n",
    "        max_prob = results_df['Fraud_Probability'].max()\n",
    "        \n",
    "        stats_text = f\"\"\"\n",
    "📊 PREDICTION SUMMARY\n",
    "\n",
    "Total Cases: {total_cases:,}\n",
    "Fraud Cases: {fraud_cases:,} ({fraud_cases/total_cases*100:.1f}%)\n",
    "\n",
    "🚨 Risk Breakdown:\n",
    "High Risk: {high_risk:,} ({high_risk/total_cases*100:.1f}%)\n",
    "Medium Risk: {medium_risk:,} ({medium_risk/total_cases*100:.1f}%)\n",
    "Low Risk: {low_risk:,} ({low_risk/total_cases*100:.1f}%)\n",
    "\n",
    "📈 Probability Stats:\n",
    "Average: {avg_prob:.4f}\n",
    "Maximum: {max_prob:.4f}\n",
    "\n",
    "⚡ Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "        \"\"\"\n",
    "        \n",
    "        plt.text(0.1, 0.9, stats_text, transform=plt.gca().transAxes, fontsize=10,\n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "        \n",
    "        # Probability vs Prediction Accuracy\n",
    "        plt.subplot(3, 4, 12)\n",
    "        fraud_probs = results_df[results_df['Fraud_Prediction'] == 1]['Fraud_Probability']\n",
    "        no_fraud_probs = results_df[results_df['Fraud_Prediction'] == 0]['Fraud_Probability']\n",
    "        \n",
    "        if len(fraud_probs) > 0:\n",
    "            plt.hist(no_fraud_probs, bins=20, alpha=0.7, label='Predicted No Fraud', color='lightblue', density=True)\n",
    "            plt.hist(fraud_probs, bins=20, alpha=0.7, label='Predicted Fraud', color='salmon', density=True)\n",
    "            plt.legend()\n",
    "        else:\n",
    "            plt.hist(results_df['Fraud_Probability'], bins=30, alpha=0.7, color='lightblue')\n",
    "        \n",
    "        plt.title('Probability Distribution by Prediction', fontsize=10, fontweight='bold')\n",
    "        plt.xlabel('Fraud Probability')\n",
    "        plt.ylabel('Density')\n",
    "        \n",
    "        plt.tight_layout(pad=3.0)\n",
    "        \n",
    "        # Save the plot\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        plot_filename = f\"fraud_prediction_analysis_{timestamp}.png\"\n",
    "        plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"   ✅ Prediction plots saved as: {plot_filename}\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the fraud detection system\n",
    "    \"\"\"\n",
    "    print(\"🚗 INSURANCE FRAUD DETECTION SYSTEM\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Initialize the system\n",
    "    fraud_system = FraudDetectionSystem()\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\n🔧 Choose an option:\")\n",
    "        print(\"1. Train new model (creates synthetic data)\")\n",
    "        print(\"2. Train model with your data\")\n",
    "        print(\"3. Predict fraud on new data\")\n",
    "        print(\"4. Exit\")\n",
    "        \n",
    "        choice = input(\"\\n➤ Enter your choice (1-4): \").strip()\n",
    "        \n",
    "        if choice == '1':\n",
    "            print(\"\\n🎯 Training model with synthetic data...\")\n",
    "            fraud_system.train_model()\n",
    "            \n",
    "        elif choice == '2':\n",
    "            print(\"\\n📁 Training model with your data...\")\n",
    "            file_path = fraud_system.get_user_input()\n",
    "            if file_path:\n",
    "                try:\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    print(f\"✅ Training data loaded: {df.shape}\")\n",
    "                    \n",
    "                    # Check if 'Fraud' column exists\n",
    "                    if 'Fraud' not in df.columns:\n",
    "                        print(\"❌ Training data must contain a 'Fraud' column with labels (0/1)\")\n",
    "                        continue\n",
    "                    \n",
    "                    fraud_system.train_model(df)\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Error loading training data: {str(e)}\")\n",
    "            \n",
    "        elif choice == '3':\n",
    "            print(\"\\n🔍 Predicting fraud on new data...\")\n",
    "            \n",
    "            # Check if model exists\n",
    "            if not os.path.exists('fraud_detection_xgb_model.pkl'):\n",
    "                print(\"❌ No trained model found!\")\n",
    "                train_now = input(\"   Would you like to train a model now? (y/n): \").strip().lower()\n",
    "                if train_now == 'y':\n",
    "                    print(\"🎯 Training model with synthetic data...\")\n",
    "                    fraud_system.train_model()\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            # Make predictions\n",
    "            results = fraud_system.predict_fraud()\n",
    "            \n",
    "            if results is not None:\n",
    "                print(\"\\n✅ Fraud prediction completed successfully!\")\n",
    "                \n",
    "                # Ask if user wants to see detailed analysis\n",
    "                show_details = input(\"\\nWould you like to see detailed case analysis? (y/n): \").strip().lower()\n",
    "                if show_details == 'y':\n",
    "                    print(\"\\n🔍 DETAILED HIGH-RISK CASE ANALYSIS:\")\n",
    "                    print(\"-\" * 50)\n",
    "                    \n",
    "                    high_risk_cases = results[results['Risk_Level'] == 'High'].nlargest(10, 'Fraud_Probability')\n",
    "                    \n",
    "                    if len(high_risk_cases) > 0:\n",
    "                        for idx, case in high_risk_cases.iterrows():\n",
    "                            print(f\"📋 Claim ID: {case['Claim_ID']}\")\n",
    "                            print(f\"   Fraud Probability: {case['Fraud_Probability']:.4f}\")\n",
    "                            print(f\"   Risk Level: {case['Risk_Level']}\")\n",
    "                            print(f\"   Prediction: {case['Fraud_Label']}\")\n",
    "                            print()\n",
    "                    else:\n",
    "                        print(\"   No high-risk cases found.\")\n",
    "            \n",
    "        elif choice == '4':\n",
    "            print(\"\\n👋 Thank you for using the Fraud Detection System!\")\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            print(\"❌ Invalid choice. Please enter 1, 2, 3, or 4.\")\n",
    "        \n",
    "        # Ask if user wants to continue\n",
    "        if choice in ['1', '2', '3']:\n",
    "            continue_choice = input(\"\\nWould you like to perform another operation? (y/n): \").strip().lower()\n",
    "            if continue_choice != 'y':\n",
    "                print(\"\\n👋 Thank you for using the Fraud Detection System!\")\n",
    "                break\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n⚠️  Operation cancelled by user.\")\n",
    "        print(\"👋 Thank you for using the Fraud Detection System!\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ An unexpected error occurred: {str(e)}\")\n",
    "        print(\"Please try again or contact support.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e59dce8-4a42-4a66-b523-fb3b62e6f550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
